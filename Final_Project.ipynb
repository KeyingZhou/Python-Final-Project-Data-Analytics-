{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1tGcX2qzS2GoaN5zFeD5DVJxqDmoQdmMs7QncZwFCEqU/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's totally optional whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_All code should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e83207",
   "metadata": {},
   "source": [
    "In this part, we import all the libraries we will use in this project and set some constants to represent the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project\n",
    "from math import radians,sin,cos,asin,sqrt\n",
    "import bs4 \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import typing\n",
    "import pytest\n",
    "import ipytest\n",
    "import re\n",
    "import csv\n",
    "from pandas.testing import assert_frame_equal\n",
    "import os.path\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants pointing to dataset\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library\n",
    "* [ ] Write at least one unit test that tests this distance calculation function. \n",
    "* Taxi data:\n",
    "    * [ ] Use `requests`, BeautifulSoup (`bs4`), and `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "    * [ ] Load the data from your local computer (using `pandas`), then clean the data, including: \n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * Remove trips that start and/or end outside the designated [coordinate box]\n",
    "* Using the function that calculates the distance between two coordinates in kilometers, add a column to each `pandas` DataFrame of data that calculates the distance between pickup and dropoff locations for each trip.\n",
    "* Weather data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "    * [ ] Load the data from your local computer (using `pandas`), then clean the data, including: \n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "        * You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what youâ€™re doing so we can follow along. \n",
    "* Take a look at the lecture notes from the `pandas` lecture for hints on helpful functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate distance and Add it to the dataset\n",
    "Step 1: Calculate the distance between two coordinates using the haversine formula:  \n",
    "Reference from Wikipedia  \n",
    "![image](https://miro.medium.com/max/1392/0*mie5h2yduk6NmIym)  \n",
    "Step 2: Add the distance  to the dataset as the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(from_coord:tuple[float,float], to_coord:tuple[float,float]) -> float:\n",
    "    #Convert decimal number to radian number\n",
    "    from_lon,from_lat,to_lon,to_lat=map(radians,[from_coord[0],from_coord[1],to_coord[0],to_coord[1]])\n",
    "    \n",
    "    #using haversin formula\n",
    "    dis_lon=to_lon-from_lon\n",
    "    dis_lat=to_lat-from_lat\n",
    "    haversine=sin(dis_lat/2)**2+cos(from_lat)*cos(to_lat)*sin(dis_lon/2)**2\n",
    "    #6371 is the earth's radius(km)\n",
    "    distance=6371*2*asin(sqrt(haversine))\n",
    "    #round the result to two decimals\n",
    "    return round(distance,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee0343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================= test session starts =======================================\n",
      "platform win32 -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- C:\\Program Files\\Python310\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: e:\\projects\\Python Final Project\n",
      "collecting ... collected 5 items\n",
      "\n",
      "tmpf9aobg6d.py::test_calculate_distance[from_coord0-to_coord0-1.68] <- C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_41772\\1071625851.py PASSED [ 20%]\n",
      "tmpf9aobg6d.py::test_calculate_distance[from_coord1-to_coord1-2.46] <- C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_41772\\1071625851.py PASSED [ 40%]\n",
      "tmpf9aobg6d.py::test_calculate_distance[from_coord2-to_coord2-11.36] <- C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_41772\\1071625851.py PASSED [ 60%]\n",
      "tmpf9aobg6d.py::test_calculate_distance[from_coord3-to_coord3-18.21] <- C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_41772\\1071625851.py PASSED [ 80%]\n",
      "tmpf9aobg6d.py::test_calculate_distance[from_coord4-to_coord4-13.12] <- C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_41772\\1071625851.py PASSED [100%]\n",
      "\n",
      "======================================== 5 passed in 0.02s ========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST FOR calculate_distance()\n",
    "#TEST BEGINS\n",
    "@pytest.mark.parametrize(\n",
    "    \"from_coord,to_coord,expected\",\n",
    "    (\n",
    "        ((-73.99981689,40.73835373),(-73.99951172,40.72321701),1.68),\n",
    "        ((-73.994355,40.728225),(-73.99471,40.750325),2.46),\n",
    "        ((-73.78808,40.642187),(-73.865042,40.725997),11.36),\n",
    "        ((-73.992122,40.748577),(-73.806072,40.665272),18.21),\n",
    "        ((-73.982321,40.768729),(-73.921654,40.660043),13.12),\n",
    "    )\n",
    ")\n",
    "\n",
    "def test_calculate_distance(from_coord:tuple[float,float],to_coord,expected:tuple[float,float]) -> None:\n",
    "    assert expected==calculate_distance(from_coord,to_coord)\n",
    "\n",
    "ipytest.run(\"-vv\", \"-k\", \"test_calculate_distance\")\n",
    "#TEST ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add distance to the dataset\n",
    "def add_distance_column(df:pd.DataFrame) -> None:\n",
    "    distance=[]\n",
    "    for i,row in df[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']].iterrows():\n",
    "        distance.append(calculate_distance((row['pickup_longitude'],row['pickup_latitude']),(row['dropoff_longitude'],row['dropoff_latitude'])))\n",
    "    df['trip_distance']=distance\n",
    "    #add distance to the new column 'trip_distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5f887b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================= test session starts =======================================\n",
      "platform win32 -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- C:\\Program Files\\Python310\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: e:\\projects\\Python Final Project\n",
      "collecting ... collected 6 items / 5 deselected / 1 selected\n",
      "\n",
      "tmpd7w_pzty.py::test_add_distance <- C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_41772\\1575671478.py PASSED [100%]\n",
      "\n",
      "================================= 1 passed, 5 deselected in 0.01s =================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST FOR add_distance_column\n",
    "# TEST BEGINS\n",
    "test_data = pd.DataFrame(\n",
    "    {\n",
    "        \"pickup_longitude\": [-73.99981689, -73.994355],\n",
    "        \"pickup_latitude\": [40.73835373, 40.728225],\n",
    "        \"dropoff_longitude\": [-73.99951172, -73.99471],\n",
    "        \"dropoff_latitude\": [40.72321701, 40.750325],\n",
    "    }\n",
    ")\n",
    "expected_data = pd.DataFrame(\n",
    "    {\n",
    "        \"pickup_longitude\": [-73.99981689, -73.994355],\n",
    "        \"pickup_latitude\": [40.73835373, 40.728225],\n",
    "        \"dropoff_longitude\": [-73.99951172, -73.99471],\n",
    "        \"dropoff_latitude\": [40.72321701, 40.750325],\n",
    "        \"trip_distance\": [1.68, 2.46],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def test_add_distance():\n",
    "    add_distance_column(test_data)\n",
    "    assert_frame_equal(test_data, expected_data)\n",
    "\n",
    "\n",
    "ipytest.run(\"-vv\", \"-k\", \"test_add_distance\")\n",
    "# TEST ENDS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "* Clean the data, including:\n",
    "  * Remove unnecessary columns\n",
    "  * Remove invalid data points\n",
    "  * Remove trips that start and/or end outside the designated NEW_YORK_BOX_COORDS  \n",
    "  \n",
    "\n",
    "* Calculate the sample size for each month and so we can use it later to sample the Yellow taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean data\n",
    "def load_and_clean_uber_data(csv_file:str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # only pick the columns that will be used later\n",
    "    df=df[['fare_amount','pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']]\n",
    "    # Remove trips that start and/or end outside the designated coordinate box\n",
    "    df = df[\n",
    "        (df[\"pickup_longitude\"] <= NEW_YORK_BOX_COORDS[1][1])\n",
    "        & (NEW_YORK_BOX_COORDS[0][1] <= df[\"pickup_longitude\"])\n",
    "        & (df[\"pickup_latitude\"] <= NEW_YORK_BOX_COORDS[1][0])\n",
    "        & (NEW_YORK_BOX_COORDS[0][0] <= df[\"pickup_latitude\"])\n",
    "        & (df[\"dropoff_longitude\"] <= NEW_YORK_BOX_COORDS[1][1])\n",
    "        & (NEW_YORK_BOX_COORDS[0][1] <= df[\"dropoff_longitude\"])\n",
    "        & (df[\"dropoff_latitude\"] <= NEW_YORK_BOX_COORDS[1][0])\n",
    "        & (NEW_YORK_BOX_COORDS[0][0] <= df[\"dropoff_latitude\"])\n",
    "    ]\n",
    "    # delete invalid data points where the fare_amount is 0\n",
    "    return df[(df[\"fare_amount\"] != 0)]\n",
    "\n",
    "# get the whole cleaned dataset\n",
    "def get_uber_data() -> pd.DataFrame:\n",
    "    # get the cleaned data and add trip_distance column to it\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6f3c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sample size for each month\n",
    "def get_sample_size(df:pd.DataFrame) -> dict:\n",
    "    #group the data by the month\n",
    "    df_month=df.groupby(df['pickup_datetime'].str[:7]).count()\n",
    "    sample_size={}\n",
    "    #store the month and sample size to the dict\n",
    "    for month, size in df_month[['fare_amount']].iterrows():\n",
    "        sample_size[month] = size.values[0]\n",
    "    return sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd3cf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all functions and get the dataset\n",
    "uber_data = get_uber_data()\n",
    "sample_size=get_sample_size(uber_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f6ad9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195470 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0               7.5  2015-05-07 19:52:06 UTC        -73.999817   \n",
       "1               7.7  2009-07-17 20:04:56 UTC        -73.994355   \n",
       "2              12.9  2009-08-24 21:45:00 UTC        -74.005043   \n",
       "3               5.3  2009-06-26 08:22:21 UTC        -73.976124   \n",
       "4              16.0  2014-08-28 17:47:00 UTC        -73.925023   \n",
       "...             ...                      ...               ...   \n",
       "199995          3.0  2012-10-28 10:49:00 UTC        -73.987042   \n",
       "199996          7.5  2014-03-14 01:09:00 UTC        -73.984722   \n",
       "199997         30.9  2009-06-29 00:42:00 UTC        -73.986017   \n",
       "199998         14.5  2015-05-20 14:56:25 UTC        -73.997124   \n",
       "199999         14.1  2010-05-15 04:08:00 UTC        -73.984395   \n",
       "\n",
       "        pickup_latitude  dropoff_longitude  dropoff_latitude  trip_distance  \n",
       "0             40.738354         -73.999512         40.723217           1.68  \n",
       "1             40.728225         -73.994710         40.750325           2.46  \n",
       "2             40.740770         -73.962565         40.772647           5.04  \n",
       "3             40.790844         -73.965316         40.803349           1.66  \n",
       "4             40.744085         -73.973082         40.761247           4.48  \n",
       "...                 ...                ...               ...            ...  \n",
       "199995        40.739367         -73.986525         40.740297           0.11  \n",
       "199996        40.736837         -74.006672         40.739620           1.88  \n",
       "199997        40.756487         -73.858957         40.692588          12.85  \n",
       "199998        40.725452         -73.983215         40.695415           3.54  \n",
       "199999        40.720077         -73.985508         40.768793           5.42  \n",
       "\n",
       "[195470 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the uber dataset\n",
    "uber_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "\n",
    "* Use `requests`, BeautifulSoup (`bs4`), and `pandas` to programmatically download the required CSV files & load into memory.\n",
    "* Clean the data, including:\n",
    "    * Remove unnecessary columns\n",
    "    * Remove invalid data points (take a moment to consider what's invalid)\n",
    "    * Normalize column names\n",
    "    * Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "* Sample the data so that we have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* Cache the sampling by saving it as a CSV file before moving onto the next file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd75da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_41772\\1139572720.py:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "url='https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-01.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fba6e7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-29 02:38:35</td>\n",
       "      <td>2011-01-29 02:47:07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-74.005254</td>\n",
       "      <td>40.729084</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.988697</td>\n",
       "      <td>40.727127</td>\n",
       "      <td>CSH</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 10:38:19</td>\n",
       "      <td>2011-01-28 10:42:18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-73.968585</td>\n",
       "      <td>40.759171</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.964336</td>\n",
       "      <td>40.764665</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 23:49:58</td>\n",
       "      <td>2011-01-28 23:57:44</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-73.980710</td>\n",
       "      <td>40.742390</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.987028</td>\n",
       "      <td>40.729532</td>\n",
       "      <td>CSH</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 23:52:09</td>\n",
       "      <td>2011-01-28 23:59:21</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-73.993773</td>\n",
       "      <td>40.747329</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.991378</td>\n",
       "      <td>40.750050</td>\n",
       "      <td>CSH</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 10:34:39</td>\n",
       "      <td>2011-01-28 11:25:50</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.991475</td>\n",
       "      <td>40.749936</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.950237</td>\n",
       "      <td>40.775626</td>\n",
       "      <td>CSH</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464991</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-26 14:56:04</td>\n",
       "      <td>2011-01-26 15:02:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-73.977775</td>\n",
       "      <td>40.787092</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.982338</td>\n",
       "      <td>40.770560</td>\n",
       "      <td>CRD</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464992</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-26 14:54:16</td>\n",
       "      <td>2011-01-26 15:00:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.990756</td>\n",
       "      <td>40.743947</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.005525</td>\n",
       "      <td>40.751080</td>\n",
       "      <td>CRD</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464993</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-26 15:28:50</td>\n",
       "      <td>2011-01-26 15:52:50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-73.991282</td>\n",
       "      <td>40.755183</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.002063</td>\n",
       "      <td>40.719173</td>\n",
       "      <td>CRD</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464994</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-27 09:54:05</td>\n",
       "      <td>2011-01-27 10:05:16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-73.978428</td>\n",
       "      <td>40.750780</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.973115</td>\n",
       "      <td>40.760543</td>\n",
       "      <td>CRD</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464995</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-26 15:28:23</td>\n",
       "      <td>2011-01-26 15:40:51</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-73.987571</td>\n",
       "      <td>40.770502</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>-73.962091</td>\n",
       "      <td>40.805377</td>\n",
       "      <td>CRD</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13464996 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         vendor_id      pickup_datetime     dropoff_datetime  passenger_count  \\\n",
       "0              CMT  2011-01-29 02:38:35  2011-01-29 02:47:07                1   \n",
       "1              CMT  2011-01-28 10:38:19  2011-01-28 10:42:18                1   \n",
       "2              CMT  2011-01-28 23:49:58  2011-01-28 23:57:44                3   \n",
       "3              CMT  2011-01-28 23:52:09  2011-01-28 23:59:21                3   \n",
       "4              CMT  2011-01-28 10:34:39  2011-01-28 11:25:50                1   \n",
       "...            ...                  ...                  ...              ...   \n",
       "13464991       CMT  2011-01-26 14:56:04  2011-01-26 15:02:52                1   \n",
       "13464992       CMT  2011-01-26 14:54:16  2011-01-26 15:00:48                1   \n",
       "13464993       CMT  2011-01-26 15:28:50  2011-01-26 15:52:50                1   \n",
       "13464994       CMT  2011-01-27 09:54:05  2011-01-27 10:05:16                1   \n",
       "13464995       CMT  2011-01-26 15:28:23  2011-01-26 15:40:51                1   \n",
       "\n",
       "          trip_distance  pickup_longitude  pickup_latitude  rate_code  \\\n",
       "0                   1.2        -74.005254        40.729084          1   \n",
       "1                   0.4        -73.968585        40.759171          1   \n",
       "2                   1.2        -73.980710        40.742390          1   \n",
       "3                   0.8        -73.993773        40.747329          1   \n",
       "4                   5.3        -73.991475        40.749936          1   \n",
       "...                 ...               ...              ...        ...   \n",
       "13464991            1.2        -73.977775        40.787092          1   \n",
       "13464992            1.0        -73.990756        40.743947          1   \n",
       "13464993            3.2        -73.991282        40.755183          1   \n",
       "13464994            1.2        -73.978428        40.750780          1   \n",
       "13464995            2.7        -73.987571        40.770502          1   \n",
       "\n",
       "         store_and_fwd_flag  dropoff_longitude  dropoff_latitude payment_type  \\\n",
       "0                         N         -73.988697         40.727127          CSH   \n",
       "1                         N         -73.964336         40.764665          CSH   \n",
       "2                         N         -73.987028         40.729532          CSH   \n",
       "3                         N         -73.991378         40.750050          CSH   \n",
       "4                         N         -73.950237         40.775626          CSH   \n",
       "...                     ...                ...               ...          ...   \n",
       "13464991                  N         -73.982338         40.770560          CRD   \n",
       "13464992                  N         -74.005525         40.751080          CRD   \n",
       "13464993                  N         -74.002063         40.719173          CRD   \n",
       "13464994                  N         -73.973115         40.760543          CRD   \n",
       "13464995                  Y         -73.962091         40.805377          CRD   \n",
       "\n",
       "          fare_amount  surcharge  mta_tax  tip_amount  tolls_amount  \\\n",
       "0                 6.1        0.5      0.5        0.00           0.0   \n",
       "1                 4.1        0.0      0.5        0.00           0.0   \n",
       "2                 6.1        0.5      0.5        0.00           0.0   \n",
       "3                 5.3        0.5      0.5        0.00           0.0   \n",
       "4                25.3        0.0      0.5        0.00           0.0   \n",
       "...               ...        ...      ...         ...           ...   \n",
       "13464991          5.7        0.0      0.5        1.25           0.0   \n",
       "13464992          5.3        0.0      0.5        0.87           0.0   \n",
       "13464993         13.7        0.0      0.5        2.13           0.0   \n",
       "13464994          7.3        0.0      0.5        1.17           0.0   \n",
       "13464995          9.3        0.0      0.5        1.96           0.0   \n",
       "\n",
       "          total_amount  \n",
       "0                 7.10  \n",
       "1                 4.60  \n",
       "2                 7.10  \n",
       "3                 6.30  \n",
       "4                25.80  \n",
       "...                ...  \n",
       "13464991          7.45  \n",
       "13464992          6.67  \n",
       "13464993         16.33  \n",
       "13464994          8.97  \n",
       "13464995         11.76  \n",
       "\n",
       "[13464996 rows x 18 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the taxi csv file urls\n",
    "def find_taxi_csv_urls() -> list:\n",
    "    taxi_page = requests.get(TAXI_URL)\n",
    "    soup = bs4.BeautifulSoup(taxi_page.text, \"html.parser\")\n",
    "    # match all the urls that are taxi csv files\n",
    "    pattern = re.compile(\n",
    "        \"https:\\/\\/s3\\.amazonaws\\.com\\/nyc-tlc\\/trip\\+data\\/yellow_tripdata_\\d{4}-\\d{2}\\.csv\"\n",
    "    )\n",
    "    all_href = [a[\"href\"] for a in soup.find_all(\"a\")]\n",
    "    all_url = pattern.findall(\"\".join(all_href))\n",
    "    all_url = all_url[54:60] + all_url[66:]\n",
    "    return all_url\n",
    "\n",
    "# Normalize all csv files to the same column names\n",
    "def normalize_col_name(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    col_names=df.columns\n",
    "    col_names=\",\".join(col_names).split(',')\n",
    "    # Set all the names to the following new names\n",
    "    col_newname=['pickup_datetime','dropoff_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','tip_amount','total_amount']\n",
    "    col_oldname=[]\n",
    "    # find all the old col names \n",
    "    pattern1=\".*time.*\"\n",
    "    pattern2=\".*lon.*\"\n",
    "    pattern3=\".*lat.*\"\n",
    "    pattern4=\".*[Tt]ip.*\"\n",
    "    pattern5=\".*[Tt]otal.*\"\n",
    "    for i in col_names:\n",
    "        if(re.findall(pattern1,i) != []):\n",
    "            col_oldname.append(re.findall(pattern1,i)[0])\n",
    "        if(re.findall(pattern2,i) != [] ):\n",
    "            col_oldname.append(re.findall(pattern2,i)[0])\n",
    "        if(re.findall(pattern3,i) != [] ):\n",
    "            col_oldname.append(re.findall(pattern3,i)[0])\n",
    "        if(re.findall(pattern4,i) != [] ):\n",
    "            col_oldname.append(re.findall(pattern4,i)[0])\n",
    "        if(re.findall(pattern5,i) != [] ):\n",
    "            col_oldname.append(re.findall(pattern5,i)[0])\n",
    "\n",
    "    name_dict=dict(zip(col_oldname,col_newname))\n",
    "    # change col names\n",
    "    df.rename(columns=name_dict,inplace=True)\n",
    "    # We only select part of the columns and remove unnecessary columns\n",
    "    return df[col_newname]\n",
    "    \n",
    "# load and clean data\n",
    "# if the csv files has been saved before, then load it directly from the computer\n",
    "def get_and_clean_month_taxi_data(url: str) -> pd.DataFrame:\n",
    "    month = url[59:66]\n",
    "    sample = sample_size[month]\n",
    "    file_exists = os.path.exists(f\"taxi_{month}.csv\")\n",
    "    # if file already saved, then load it from the computer\n",
    "    if file_exists == True:\n",
    "        df = pd.read_csv(f\"taxi_{month}.csv\")\n",
    "    # if file haven't been saved, then load it from the URL.\n",
    "    else:\n",
    "        df = pd.read_csv(url)\n",
    "        df = df[(df[\"total_amount\"] != 0)]\n",
    "        df = df[\n",
    "            (df[\"pickup_longitude\"] <= NEW_YORK_BOX_COORDS[1][1])\n",
    "            & (NEW_YORK_BOX_COORDS[0][1] <= df[\"pickup_longitude\"])\n",
    "            & (df[\"pickup_latitude\"] <= NEW_YORK_BOX_COORDS[1][0])\n",
    "            & (NEW_YORK_BOX_COORDS[0][0] <= df[\"pickup_latitude\"])\n",
    "            & (df[\"dropoff_longitude\"] <= NEW_YORK_BOX_COORDS[1][1])\n",
    "            & (NEW_YORK_BOX_COORDS[0][1] <= df[\"dropoff_longitude\"])\n",
    "            & (df[\"dropoff_latitude\"] <= NEW_YORK_BOX_COORDS[1][0])\n",
    "            & (NEW_YORK_BOX_COORDS[0][0] <= df[\"dropoff_latitude\"])\n",
    "        ]\n",
    "        # Normalize the col names and delete other unnecessary columns\n",
    "        df=normalize_col_name(df)\n",
    "        # Sample the data so that we have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "        df = df.sample(n=sample, random_state=1)\n",
    "        df.to_csv(f\"taxi_{month}.csv\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    all_csv_urls = find_taxi_csv_urls()\n",
    "    for csv_url in all_csv_urls:\n",
    "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "        add_distance_column(dataframe)\n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "\n",
    "    taxi_data = pd.contact(all_taxi_dataframes)\n",
    "    return taxi_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34016ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    \n",
    "\n",
    "def clean_month_weather_data_daily(csv_file):\n",
    "    \n",
    "\n",
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "\n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\"TODO\"]\n",
    "\n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "\n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    return hourly_data, daily_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hourly_weather, daily_weather = load_and_clean_weather_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands\n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "TODO \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes_to_table():\n",
    "    raise NotImplemented()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}\n",
    "\n",
    "dataframes_to_table(table_name_to_dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplemented()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query N\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_N = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_N).fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_N, \"some_descriptive_name.sql\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "* [ ] Come up with 3 questions on your own that can be answered based on the data in the 4 tables. Create at least one visualization to answer each question. At least one visualization should require data from at least 3 tables.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_You don't have to query the data directly from the database. You can just re-use the pandas DataFrame that you created in Part 1._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "\n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other\n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style\n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visual_n(some_dataframe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
